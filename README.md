## Загальний опис виконаної роботи та висновки

Усі три надані PySpark програми мають на меті обробку даних з CSV-файлу. Основні кроки обробки включають завантаження даних, перерозподіл партицій, фільтрацію за умовою `final_priority < 3`, групування за `unit_id` з підрахунком кількості елементів у кожній групі, та подальшу фільтрацію груп, де ця кількість перевищує 2.

Ключова відмінність між програмами полягає в стратегії виконання обчислень, що визначається моментами виклику Spark actions (як `collect()`) та використанням механізму кешування (`.cache()`). Ці відмінності безпосередньо впливають на кількість Spark Jobs, що запускаються, та на загальну ефективність обробки.

## Висновки щодо кількості Spark Jobs та впливу кешування

Аналіз роботи наданих програм дозволяє сформулювати наступні висновки стосовно того, як Spark виконує завдання та як кешування впливає на кількість Spark Jobs:

1.  **Початкові Jobs:** Завантаження даних, особливо з опціями на кшталт автоматичного визначення схеми (`inferSchema`), може призводити до виконання початкових Spark Jobs ще до основних обчислень, визначених користувачем.

2.  **Дії (`Actions`) генерують Jobs:** Кожна дія, що викликається на DataFrame (наприклад, `collect()`), ініціює реальне виконання всіх запланованих "лінивих" трансформацій. Це призводить до запуску одного або декількох Spark Jobs. Кількість jobs, пов'язаних з однією дією, може варіюватися залежно від складності обчислювального графу (DAG), наявності операцій, що вимагають перетасування даних (shuffle operations, як `repartition` або `groupBy`), та внутрішньої оптимізації Spark.

3.  **Вплив послідовних дій без кешування:** Якщо DataFrame використовується у кількох послідовних діях без попереднього кешування, Spark буде змушений переобчислювати цей DataFrame (разом з усіма попередніми трансформаціями) кожного разу, коли викликається нова дія. Це може призвести до значної кількості повторюваних обчислень і, відповідно, більшої загальної кількості jobs.

4.  **Роль кешування (`.cache()`):**
    * **Зменшення обчислень:** Коли DataFrame кешується за допомогою `.cache()` (або `.persist()`), його вміст матеріалізується в пам'яті (або на диску, залежно від рівня зберігання) під час виконання першої дії над ним.
    * **Оптимізація наступних дій:** При наступних зверненнях до цього кешованого DataFrame для виконання інших дій, Spark може зчитувати дані безпосередньо з кешу, уникаючи повного переобчислення всіх попередніх трансформацій.
    * **Зменшення кількості Jobs:** Як наслідок, використання кешованих даних для наступних дій не тільки значно прискорює їх виконання, але й може призвести до **зменшення кількості Spark Jobs** (або, точніше, кількості стадій, з яких складаються ці jobs). Це відбувається тому, що Spark може пропустити виконання тих стадій, результати яких вже доступні в кеші, тим самим спрощуючи та скорочуючи план виконання для наступних операцій.

5.  **Ефективність робочого процесу:** Для оптимізації Spark-додатків, де проміжні результати обробки даних використовуються багаторазово, стратегічне використання кешування є ключовим. Це дозволяє не тільки підвищити швидкість виконання, але й зменшити загальне навантаження на кластер шляхом уникнення повторних обчислень і потенційного скорочення кількості виконуваних jobs.